{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6da9a4d0-cfb8-4d16-8857-0dcb80da57c3",
   "metadata": {},
   "source": [
    "## Setup & Installation\n",
    "##### Prerequisites:\n",
    "Before you begin, ensure you have:\n",
    "\n",
    "##### Google Cloud SDK installed if you intend to use Google Cloud Services.\n",
    "##### Appropriate permissions to install python packages and libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0e4f6632-07bf-48a6-8d76-2744119cd7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /opt/conda/lib/python3.10/site-packages (1.27.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.1.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.8.0)\n",
      "Requirement already satisfied: numpy<2,>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (1.23.5)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in /opt/conda/lib/python3.10/site-packages (from streamlit) (23.1)\n",
      "Requirement already satisfied: pandas<3,>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.0.3)\n",
      "Requirement already satisfied: pillow<10,>=7.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=6.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (12.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.18 in /opt/conda/lib/python3.10/site-packages (from streamlit) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (13.5.2)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from streamlit) (4.7.1)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in /opt/conda/lib/python3.10/site-packages (from streamlit) (5.0.1)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.1.32)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /opt/conda/lib/python3.10/site-packages (from streamlit) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /opt/conda/lib/python3.10/site-packages (from streamlit) (6.3.3)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in /opt/conda/lib/python3.10/site-packages (from streamlit) (3.0.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.19.0)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7,>=1.4->streamlit) (3.16.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3,>=1.3.0->streamlit) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.18->streamlit) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.18->streamlit) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.18->streamlit) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.18->streamlit) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.9.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: google-cloud in /opt/conda/lib/python3.10/site-packages (0.34.0)\n",
      "Requirement already satisfied: asyncio in /opt/conda/lib/python3.10/site-packages (3.4.3)\n",
      "Requirement already satisfied: asyncpg in /opt/conda/lib/python3.10/site-packages (0.27.0)\n",
      "Requirement already satisfied: cloud-sql-python-connector[asyncpg]==1.2.3 in /opt/conda/lib/python3.10/site-packages (1.2.3)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from cloud-sql-python-connector[asyncpg]==1.2.3) (3.8.5)\n",
      "Requirement already satisfied: cryptography>=38.0.3 in /opt/conda/lib/python3.10/site-packages (from cloud-sql-python-connector[asyncpg]==1.2.3) (41.0.3)\n",
      "Requirement already satisfied: Requests in /opt/conda/lib/python3.10/site-packages (from cloud-sql-python-connector[asyncpg]==1.2.3) (2.31.0)\n",
      "Requirement already satisfied: google-auth in /opt/conda/lib/python3.10/site-packages (from cloud-sql-python-connector[asyncpg]==1.2.3) (2.22.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=38.0.3->cloud-sql-python-connector[asyncpg]==1.2.3) (1.15.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector[asyncpg]==1.2.3) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector[asyncpg]==1.2.3) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector[asyncpg]==1.2.3) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector[asyncpg]==1.2.3) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector[asyncpg]==1.2.3) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector[asyncpg]==1.2.3) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector[asyncpg]==1.2.3) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth->cloud-sql-python-connector[asyncpg]==1.2.3) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth->cloud-sql-python-connector[asyncpg]==1.2.3) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth->cloud-sql-python-connector[asyncpg]==1.2.3) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth->cloud-sql-python-connector[asyncpg]==1.2.3) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth->cloud-sql-python-connector[asyncpg]==1.2.3) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from Requests->cloud-sql-python-connector[asyncpg]==1.2.3) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from Requests->cloud-sql-python-connector[asyncpg]==1.2.3) (2023.7.22)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=38.0.3->cloud-sql-python-connector[asyncpg]==1.2.3) (2.21)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth->cloud-sql-python-connector[asyncpg]==1.2.3) (0.5.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: pgvector in /opt/conda/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pgvector) (1.23.5)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.0.300)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.20)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.7.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.40)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.6)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/conda/lib/python3.10/site-packages (1.31.0)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.34.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.22.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.20.3)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (23.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (2.10.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (3.11.4)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.10.3)\n",
      "Requirement already satisfied: shapely<2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform) (1.8.5.post1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.60.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.22.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2.31.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.57.0)\n",
      "Requirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.48.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.3.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.5.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.8.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.26.16)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.10/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (2023.7.22)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (0.5.0)\n",
      "Requirement already satisfied: shapely in /opt/conda/lib/python3.10/site-packages (1.8.5.post1)\n",
      "Requirement already satisfied: pg8000 in /opt/conda/lib/python3.10/site-packages (1.30.2)\n",
      "Requirement already satisfied: scramp>=1.4.4 in /opt/conda/lib/python3.10/site-packages (from pg8000) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pg8000) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pg8000) (1.16.0)\n",
      "Requirement already satisfied: asn1crypto>=1.5.1 in /opt/conda/lib/python3.10/site-packages (from scramp>=1.4.4->pg8000) (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n",
    "!pip install google-cloud\n",
    "!pip install asyncio asyncpg cloud-sql-python-connector[\"asyncpg\"]==1.2.3\n",
    "!pip install numpy pandas\n",
    "!pip install pgvector\n",
    "!pip install langchain transformers\n",
    "!pip install google-cloud-aiplatform\n",
    "!pip install shapely\n",
    "!pip install pg8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c383cf6-60a2-41af-a8cd-958ddb744061",
   "metadata": {},
   "source": [
    "\n",
    "**Note**: Installing packages globally may lead to conflicts. Use virtual environments (`venv` or `conda`) for isolation.\n",
    "\n",
    "#### **2. Importing Necessary Libraries**\n",
    "\n",
    "Ensure the following libraries are imported:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "337e0f15-29dc-4aa8-afe9-b98cfe343a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.sql.connector import Connector\n",
    "import pg8000\n",
    "import time\n",
    "import os\n",
    "import asyncio\n",
    "import asyncpg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import vertexai\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "import sqlalchemy\n",
    "from pgvector.asyncpg import register_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa2f38e-2600-45dd-a8a0-5150f7d95e54",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Project information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ab96a81-95a3-453d-9a0a-e44af73c6548",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = os.getenv('PROJECT_ID')\n",
    "LOCATION = os.getenv('LOCATION')\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabf95c-8b28-49e2-941a-10ba20dac67c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Database Credentials:\n",
    "\n",
    "Never hardcode database credentials. Instead, fetch them from environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63f31f51-3511-4331-8a82-7e17ee3ff5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export PROJECT_ID=\"your_project_id\"\n",
    "# export LOCATION=\"your_location\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5b54d9e-2fe5-412c-a135-0bf7cd2a5152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4f2c508-966b-46bd-bfca-069b83248dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = \"YOUR Project ID\"\n",
    "region = \"Your region\"\n",
    "instance_name = \"CloudSQL instance name\"\n",
    "\n",
    "database_name = \"DB NAME\"\n",
    "database_user = \"YOUR USER NAME\"      ###### change your own\n",
    "database_password = \"YOU PASSWORD\"  ###### change your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44c4fb55-e861-4952-9b06-7f3983916e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = os.getenv('DATABASE_NAME')\n",
    "database_user = os.getenv('DATABASE_USER')\n",
    "database_password = os.getenv('DATABASE_PASSWORD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e1a8123-cd4b-4e72-a347-ebf23e1e6828",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"INSTANCE_CONNECTION_NAME\"] = \"project-ID:region:DB-instance-name\"\n",
    "os.environ[\"DB_USER\"] = \"YOUR USER NAME\"\n",
    "os.environ[\"DB_PASS\"] = \"YOUR PASSWORD\"\n",
    "os.environ[\"DB_NAME\"] = \"DB TABLE NAME\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "edea11ce-3bb8-4c9b-9115-5d770dcc8602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project-ID:region:DB-instance-name\n",
      "YOUR USER NAME\n",
      "YOUR PASSWORD\n",
      "DB TABLE NAME\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"INSTANCE_CONNECTION_NAME\"))\n",
    "print(os.getenv(\"DB_USER\"))\n",
    "print(os.getenv(\"DB_PASS\"))\n",
    "print(os.getenv(\"DB_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e1185d8-15f5-419f-9c6e-4a5a059ed823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data\n",
    "with open(\"ry_bug.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "\n",
    "data_points = data[\"issues\"]\n",
    "\n",
    "# Extract the relevant fields and append to the list\n",
    "rows = []\n",
    "for point in data_points:\n",
    "    custom_fields_str = ' '.join([f\"{k}: {v}\" for k, v in point[\"Custom Fields\"].items()])\n",
    "    content = point[\"Subject\"] + \" \" + point[\"Description\"] + \" \" + custom_fields_str\n",
    "    rows.append([\n",
    "        point[\"Ticket ID\"], \n",
    "        point[\"Subject\"], \n",
    "        point[\"Description\"], \n",
    "        point[\"Resolution\"], \n",
    "        point[\"Current Behavior\"], \n",
    "        point[\"Solution\"], \n",
    "        content\n",
    "    ])\n",
    "\n",
    "# Convert to DataFrame\n",
    "columns = [\"Ticket ID\", \"Subject\", \"Description\", \"Resolution\", \"Current Behavior\", \"Solution\", \"Content\"]\n",
    "df = pd.DataFrame(rows, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "387dc4cd-944b-47b0-96d8-e85de6c3142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_instance(issue):\n",
    "    \"\"\"Prepare instance with task type, title, and content\"\"\"\n",
    "    custom_fields_str = ' '.join([f\"{k}: {v}\" for k, v in issue[\"Custom Fields\"].items()])\n",
    "    \n",
    "    content = issue[\"Subject\"] + \" \" + issue[\"Description\"] + \" \" + custom_fields_str + \\\n",
    "              \" \" + issue[\"Resolution\"] + \" \"+ issue[\"Solution\"]\n",
    "        \n",
    "    return {\n",
    "        \"task_type\": \"RETRIEVAL_DOCUMENT\",\n",
    "        \"title\": issue[\"Subject\"],\n",
    "        \"content\": content\n",
    "    }\n",
    "\n",
    "instances = [prepare_instance(issue) for issue in data[\"issues\"]]\n",
    "\n",
    "def chunkify(lst, chunk_size):\n",
    "    \"\"\"Break up the list lst into chunks of chunk_size.\"\"\"\n",
    "    return [lst[i:i + chunk_size] for i in range(0, len(lst), chunk_size)]\n",
    "\n",
    "def get_embeddings_for_tickets(instances):\n",
    "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-multilingual@latest\")\n",
    "    all_embeddings = []\n",
    "\n",
    "    for chunk in chunkify(instances, 5):\n",
    "        embeddings_chunk = model.get_embeddings([instance['content'] for instance in chunk])\n",
    "        all_embeddings.extend([list(embedding.values) for embedding in embeddings_chunk])\n",
    "\n",
    "    return all_embeddings\n",
    "\n",
    "ticket_embeddings = get_embeddings_for_tickets(instances)\n",
    "\n",
    "def get_embedding_for_content(content):\n",
    "    instance = {\n",
    "        \"task_type\": \"RETRIEVAL_DOCUMENT\",\n",
    "        \"content\": content\n",
    "    }\n",
    "    embedding = get_embeddings_for_tickets([instance])[0]\n",
    "    return embedding\n",
    "\n",
    "df['Embedding'] = df['Content'].apply(get_embedding_for_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58223675-bfcd-4aa6-8931-a9391b6d8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Implementing the search_similar_tickets function\n",
    "def search_similar_tickets(query, ticket_embeddings, issues, top_n=5):\n",
    "    query_instance = {\n",
    "        \"task_type\": \"RETRIEVAL_QUERY\",\n",
    "        \"content\": query\n",
    "    }\n",
    "    query_embedding = get_embeddings_for_tickets([query_instance])[0]\n",
    "    \n",
    "    # Calculate similarity between query and all tickets\n",
    "    similarity_scores = [sum(a*b for a, b in zip(query_embedding, ticket_embedding)) for ticket_embedding in ticket_embeddings]\n",
    "    \n",
    "    # Get indices of top_n most similar tickets\n",
    "    top_indices = sorted(range(len(similarity_scores)), key=lambda i: similarity_scores[i], reverse=True)[:top_n]\n",
    "    \n",
    "    # Return the actual tickets corresponding to these indices\n",
    "    return [issues[i] for i in top_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff239929-9669-49bf-8c13-a929b8a8ff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticket ID: TKT-1016\n",
      "Subject: [HQA] [IEEE]100M return loss margin is less than 5%\n",
      "Description: 100M return loss margin is less than 5%\n",
      "Customer Name: Quality Assurance Team\n",
      "Solution: Hardware adjustments and firmware tuning\n",
      "------------\n",
      "Ticket ID: TKT-1007\n",
      "Subject: [HQA][IEEE]5G Return loss Fail.\n",
      "Description: 1G Return loss Fail.\n",
      "\n",
      "Fail item\n",
      "\n",
      "Port 1 B\n",
      "Port 5 B\n",
      "Port 7 A \n",
      "Port 8 D\n",
      "Port 10 B \n",
      "Port 13 B\n",
      "Port 14 B\n",
      "Port 17 B\n",
      "Port 18 B\n",
      "Port 19 B\n",
      "Port 20 B\n",
      "Port 21 B D\n",
      "Port 22 B\n",
      "\n",
      "Customer Name: Li Wei\n",
      "Solution: Swapped out the faulty Ethernet controller chip on the identified units. Successful tests after replacement.\n",
      "------------\n",
      "Ticket ID: TKT-1003\n",
      "Subject: [HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed\n",
      "Description: 1000 Base-T, Jitter MASTER Filtered failed\n",
      "Customer Name: Michael Johnson\n",
      "Solution: NA (Pending further investigation)\n",
      "------------\n",
      "Ticket ID: TKT-1023\n",
      "Subject: [HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed\n",
      "Description: 1000 Base-T, Jitter MASTER Filtered failed\n",
      "Customer Name: Hardware Quality Assurance Team\n",
      "Solution: Evaluate the transformer and related components\n",
      "------------\n",
      "Ticket ID: TKT-1005\n",
      "Subject: [EIT] CB_EX3052R_P_USB_Sync Field Length Test Fail\n",
      "Description: 驗證CB_EEDC52RD_P_USB\n",
      "其中Sync Field Length Test時間偏短:44.325ns(SPEC:65.62~67.7ns)\n",
      "Customer Name: William Taylor\n",
      "Solution: NA (Pending further investigation)\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "query = \"100M return loss\"\n",
    "similar_issues = search_similar_tickets(query, ticket_embeddings, data[\"issues\"])\n",
    "\n",
    "# Printing the top 5 similar issues\n",
    "for issue in similar_issues:\n",
    "    print(f\"Ticket ID: {issue['Ticket ID']}\")\n",
    "    print(f\"Subject: {issue['Subject']}\")\n",
    "    print(f\"Description: {issue['Description']}\")\n",
    "    print(f\"Customer Name: {issue['Customer Name']}\")\n",
    "    print(f\"Solution: {issue['Solution']}\")\n",
    "    print(\"------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5364dbee-cf3b-48ca-888d-ca37a001c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud.sql.connector import Connector\n",
    "import sqlalchemy\n",
    "\n",
    "COLUMNS = {\n",
    "    \"Ticket Number\": 0,\n",
    "    \"Subject\": 1,\n",
    "    \"Description\": 2,\n",
    "    \"Resolution\": 3,\n",
    "    \"Current Behavior\": 4,\n",
    "    \"Solution\": 5,\n",
    "    \"Content\": 6,\n",
    "    \"Similarity\": 7\n",
    "}\n",
    "\n",
    "def connect_with_connector() -> sqlalchemy.engine.base.Engine:\n",
    "    connector = Connector()\n",
    "    return sqlalchemy.create_engine(\n",
    "        \"postgresql+pg8000://\",\n",
    "        creator=lambda: connector.connect(\n",
    "            os.getenv(\"INSTANCE_CONNECTION_NAME\"),\n",
    "            \"pg8000\",\n",
    "            user=os.getenv(\"DB_USER\"),\n",
    "            password=os.getenv(\"DB_PASS\"),\n",
    "            db=os.getenv(\"DB_NAME\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "# def get_embedding_for_query(query: str):\n",
    "#     model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-multilingual@latest\")\n",
    "#     instance = {\"task_type\": \"RETRIEVAL_QUERY\", \"content\": query}\n",
    "#     return model.get_embeddings([instance])[0].values\n",
    "\n",
    "def get_embedding_for_query(query: str):\n",
    "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-multilingual@latest\")\n",
    "    instance = {\n",
    "        \"instances\": [{\n",
    "            \"task_type\": \"RETRIEVAL_QUERY\",\n",
    "            \"content\": query\n",
    "        }]\n",
    "    }\n",
    "    embeddings = model.get_embeddings(instance)\n",
    "    return embeddings[0].values\n",
    "\n",
    "\n",
    "\n",
    "def search_similar_tickets(user_query: str, \n",
    "                           search_method: str = \"cosine\",\n",
    "                           similarity_threshold: float = 0.001,\n",
    "                           num_matches: int = 6) -> list:\n",
    "    assert user_query, \"⚠️ Please input a valid search query\"\n",
    "\n",
    "    qe = get_embedding_for_query(user_query)\n",
    "    distance_function = {\n",
    "        \"cosine\": \"<=>\",\n",
    "        \"inner_product\": \"<#>\",\n",
    "        \"euclidean\": \"<->\"\n",
    "    }.get(search_method, \"<=>\")\n",
    "\n",
    "    with connect_with_connector().connect() as db_conn:\n",
    "        query = f\"\"\"\n",
    "            WITH vector_matches AS (\n",
    "                SELECT ticket_number, 1 - (embedding {distance_function} :embedding) AS similarity\n",
    "                FROM ticket_data\n",
    "                WHERE 1 - (embedding {distance_function} :embedding) > :similarity_threshold\n",
    "                ORDER BY similarity DESC\n",
    "                LIMIT :num_matches\n",
    "            )\n",
    "            SELECT \n",
    "                t.ticket_number, t.subject, t.description, t.resolution,\n",
    "                t.current_behavior, t.solution, t.content, vm.similarity\n",
    "            FROM ticket_data AS t\n",
    "            JOIN vector_matches AS vm ON t.ticket_number = vm.ticket_number\n",
    "        \"\"\"\n",
    "\n",
    "        parameters = {\n",
    "            \"embedding\": \"[\" + \",\".join(map(str, qe)) + \"]\",\n",
    "            \"similarity_threshold\": similarity_threshold,\n",
    "            \"num_matches\": num_matches\n",
    "        }\n",
    "\n",
    "        results = db_conn.execute(sqlalchemy.text(query), parameters).fetchall()\n",
    "        matches = [\n",
    "            {column_name: row[index] for column_name, index in COLUMNS.items()}\n",
    "            for row in results\n",
    "        ]\n",
    "\n",
    "    return matches\n",
    "\n",
    "# Sample Call\n",
    "tickets = search_similar_tickets(user_query=\"100M isn't work well, reall bad\")\n",
    "print(tickets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48a66821-a85a-4265-9c59-a5eaefe2564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beautiful priting function, doesn't really matter.\n",
    "def print_tickets(tickets: list):\n",
    "    \"\"\"\n",
    "    Nicely prints the list of tickets.\n",
    "    \"\"\"\n",
    "    for idx, ticket in enumerate(tickets, start=1):\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Ticket #{idx}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for key, value in ticket.items():\n",
    "            # Beautify certain lengthy fields to display better.\n",
    "            if key in [\"Description\", \"Content\", \"Current Behavior\", \"Solution\"]:\n",
    "                value = \"\\n\\t\" + \"\\n\\t\".join(value.splitlines())\n",
    "\n",
    "            # Format the similarity score to be more readable.\n",
    "            if key == \"Similarity\":\n",
    "                value = f\"{value:.4f}\"\n",
    "\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "# Sample Call\n",
    "print_tickets(tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a65b512-f2c3-463f-a8d4-e538756fa38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Ticket #1\n",
      "==================================================\n",
      "Ticket Number: TKT-1003\n",
      "Subject: [HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed\n",
      "Description: \n",
      "\t1000 Base-T, Jitter MASTER Filtered failed\n",
      "Resolution: NA\n",
      "Current Behavior: \n",
      "\tDuring testing, the 1000 Base-T, Jitter MASTER Filtered failed.\n",
      "Solution: \n",
      "\tNA (Pending further investigation)\n",
      "Content: \n",
      "\t[HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed 1000 Base-T, Jitter MASTER Filtered failed Stage: PVT customer model: CM-9810 HW-Model: HW-MK2.8 HW - CPU Board: Intel i7-10700K HW - Main Board: MB-V2.2 SW - Boot Loader: BL-v3.2 DW - NOS/Diag Ver.: Diag-1.8.6\n",
      "Similarity: 0.5825\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ticket #2\n",
      "==================================================\n",
      "Ticket Number: TKT-1007\n",
      "Subject: [HQA][IEEE]1G Return loss Fail.\n",
      "Description: \n",
      "\t1G Return loss Fail.\n",
      "\t\n",
      "\tFail item\n",
      "\t\n",
      "\tPort 1 B\n",
      "\tPort 5 B\n",
      "\tPort 7 A \n",
      "\tPort 8 D\n",
      "\tPort 10 B \n",
      "\tPort 13 B\n",
      "\tPort 14 B\n",
      "\tPort 17 B\n",
      "\tPort 18 B\n",
      "\tPort 19 B\n",
      "\tPort 20 B\n",
      "\tPort 21 B D\n",
      "\tPort 22 B\n",
      "Resolution: Replaced the defective Ethernet controller chip. Re-tested to confirm resolution.\n",
      "Current Behavior: \n",
      "\tDuring the 1G Return loss test, multiple ports showcased failure.\n",
      "Solution: \n",
      "\tSwapped out the faulty Ethernet controller chip on the identified units. Successful tests after replacement.\n",
      "Content: \n",
      "\t[HQA][IEEE]1G Return loss Fail. 1G Return loss Fail.\n",
      "\t\n",
      "\tFail item\n",
      "\t\n",
      "\tPort 1 B\n",
      "\tPort 5 B\n",
      "\tPort 7 A \n",
      "\tPort 8 D\n",
      "\tPort 10 B \n",
      "\tPort 13 B\n",
      "\tPort 14 B\n",
      "\tPort 17 B\n",
      "\tPort 18 B\n",
      "\tPort 19 B\n",
      "\tPort 20 B\n",
      "\tPort 21 B D\n",
      "\tPort 22 B\n",
      "\t Stage: PVT customer model: CM-9812 HW-Model: HW-MK3.0 HW - CPU Board: AMD Ryzen 7 3800X HW - Main Board: MB-V3.2 SW - Boot Loader: BL-v4.1 DW - NOS/Diag Ver.: Diag-2.1.0\n",
      "Similarity: 0.5601\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ticket #3\n",
      "==================================================\n",
      "Ticket Number: TKT-1010\n",
      "Subject: [HQA] Overheating observed in CPU intensive tasks\n",
      "Description: \n",
      "\tDuring CPU intensive tasks, the temperature rose to 90°C. This was observed during a 3D rendering task using software 'Blender'.\n",
      "Resolution: Enhanced thermal dissipation by upgrading the cooling system. Also, applied high-quality thermal paste.\n",
      "Current Behavior: \n",
      "\tDevice gets excessively hot when running CPU intensive tasks.\n",
      "Solution: \n",
      "\tUpgraded the cooling system and applied a high-quality thermal paste. Subsequent tests show temperatures well within the safe range.\n",
      "Content: \n",
      "\t[HQA] Overheating observed in CPU intensive tasks During CPU intensive tasks, the temperature rose to 90°C. This was observed during a 3D rendering task using software 'Blender'. Stage: DVT customer model: CM-9801 HW-Model: HW-MK2.8 HW - CPU Board: Intel i9-10900K HW - Main Board: MB-V2.6 SW - Boot Loader: BL-v3.5 DW - NOS/Diag Ver.: Diag-1.7.2\n",
      "Similarity: 0.5698\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ticket #4\n",
      "==================================================\n",
      "Ticket Number: TKT-1011\n",
      "Subject: [EIT]3V3 Power Rail Startup Transients (Rise time fail)\n",
      "Description: \n",
      "\tST-ALTA-Switch-24PoE Power Rail Startup Transients List as below:\n",
      "\t\n",
      "\t3V3 Rise time fail\n",
      "\tTest Result = 0.321 ms (RTL9301 Spec.>0.5 ms)\n",
      "Resolution: \n",
      "Current Behavior: \n",
      "\t3V3 rise time doesn't meet the RTL9301 specification.\n",
      "Solution: \n",
      "\t\n",
      "Content: \n",
      "\t[EIT]3V3 Power Rail Startup Transients (Rise time fail) ST-ALTA-Switch-24PoE Power Rail Startup Transients List as below:\n",
      "\t\n",
      "\t3V3 Rise time fail\n",
      "\tTest Result = 0.321 ms (RTL9301 Spec.>0.5 ms) Stage: DVT customer model: ST-ALTA-Switch-24PoE HW-Model: HW-RTM3.1 Switch MAC: N/A Associated SKU: N/A Switch Firmware Version: N/A\n",
      "Similarity: 0.5679\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ticket #5\n",
      "==================================================\n",
      "Ticket Number: TKT-1013\n",
      "Subject: [EIT] CB_EX3028R_P_Interrupt訊號有異\n",
      "Description: \n",
      "\tCB_EX3028R Interrupt\n",
      "\tINTn_CPLD_Master_A訊號在回復時，會High兩次，正常情況要直接拉High\n",
      "\t參考如附件:INTn_CPLD_Master_A\n",
      "Resolution: \n",
      "Current Behavior: \n",
      "\tInterrupt signal INTn_CPLD_Master_A shows unexpected behavior during recovery.\n",
      "Solution: \n",
      "\t\n",
      "Content: \n",
      "\t[EIT] CB_EX3028R_P_Interrupt訊號有異 CB_EX3028R Interrupt\n",
      "\tINTn_CPLD_Master_A訊號在回復時，會High兩次，正常情況要直接拉High\n",
      "\t參考如附件:INTn_CPLD_Master_A Stage: MP customer model: CB_EX3028R HW-Model: HW-CBM1.2 Switch MAC: N/A Associated SKU: N/A Switch Firmware Version: N/A\n",
      "Similarity: 0.5765\n",
      "\n",
      "\n",
      "\n",
      "==================================================\n",
      "Ticket #6\n",
      "==================================================\n",
      "Ticket Number: TKT-1023\n",
      "Subject: [HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed\n",
      "Description: \n",
      "\t1000 Base-T, Jitter MASTER Filtered failed\n",
      "Resolution: \n",
      "Current Behavior: \n",
      "\tJitter MASTER filter test for 1000 Base-T failed.\n",
      "Solution: \n",
      "\tEvaluate the transformer and related components\n",
      "Content: \n",
      "\t[HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed 1000 Base-T, Jitter MASTER Filtered failed Stage: EVT Customer Model: ST-ALTA-Switch-32PoE HW-Model: HW-ALTA3.0 HW - CPU Board: CPU-B7 HW - Main Board: MB-ALTA4 SW - Boot Loader: v1.7.1 SW - NOS/Diag Ver.: 2.8.0\n",
      "Similarity: 0.5686\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Beautiful priting function, doesn't really matter.\n",
    "def print_tickets(tickets: list):\n",
    "    \"\"\"\n",
    "    Nicely prints the list of tickets.\n",
    "    \"\"\"\n",
    "    for idx, ticket in enumerate(tickets, start=1):\n",
    "        print(\"=\"*50)\n",
    "        print(f\"Ticket #{idx}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        for key, value in ticket.items():\n",
    "            # Beautify certain lengthy fields to display better.\n",
    "            if key in [\"Description\", \"Content\", \"Current Behavior\", \"Solution\"]:\n",
    "                value = \"\\n\\t\" + \"\\n\\t\".join(value.splitlines())\n",
    "\n",
    "            # Format the similarity score to be more readable.\n",
    "            if key == \"Similarity\":\n",
    "                value = f\"{value:.4f}\"\n",
    "\n",
    "            print(f\"{key}: {value}\")\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "# Sample Call\n",
    "print_tickets(tickets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbbadb34-2f0b-43f4-89f4-1331701fb03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:   高壓測試失敗，以太網隔離失敗\n",
      "     高壓測試失敗，以太網隔離測試失敗\n",
      "     高壓測試不通過，以太網隔離測試失敗\n",
      "     High-pot test fail, Ethernet isolation test fail\n",
      "     Hi-pot test fail and Ethernet isolation fail\n",
      "\n",
      "Original Input: 2000台伺服器已損壞\n",
      "Output:\n",
      "2000台伺服器已損壞\n",
      "2000台伺服器損壞\n",
      "2000台伺服器故障\n",
      "2000 servers are broken\n",
      "2000 servers are damaged\n",
      "\n",
      "Original Input: 硬碟損壞\n",
      "Output:\n",
      "硬碟損壞\n",
      "硬碟故障\n",
      "硬碟壞軌\n",
      "Hard drive corruption\n",
      "Hard drive failure\n",
      "\n",
      "Original Input: 伺服器過熱\n",
      "Output:\n",
      "伺服器過熱\n",
      "伺服器溫度過高\n",
      "伺服器散熱不良\n",
      "Server overheating\n",
      "Server temperature too high\n",
      "\n",
      "queries:  [' 高壓測試失敗，以太網隔離失敗', '     高壓測試失敗，以太網隔離測試失敗', '     高壓測試不通過，以太網隔離測試失敗', '     High-pot test fail, Ethernet isolation test fail', '     Hi-pot test fail and Ethernet isolation fail']\n",
      " 高壓測試失敗，以太網隔離失敗     ===>  TKT-1003 0.5825122138382944\n",
      " 高壓測試失敗，以太網隔離失敗     ===>  TKT-1007 0.560131003162113\n",
      " 高壓測試失敗，以太網隔離失敗     ===>  TKT-1010 0.5698104075394201\n",
      " 高壓測試失敗，以太網隔離失敗     ===>  TKT-1011 0.5679488905318236\n",
      " 高壓測試失敗，以太網隔離失敗     ===>  TKT-1013 0.5764910303659511\n",
      " 高壓測試失敗，以太網隔離失敗     ===>  TKT-1023 0.56857286296233\n",
      "     高壓測試失敗，以太網隔離測試失敗     ===>  TKT-1003 0.5825122138382944\n",
      "     高壓測試失敗，以太網隔離測試失敗     ===>  TKT-1007 0.560131003162113\n",
      "     高壓測試失敗，以太網隔離測試失敗     ===>  TKT-1010 0.5698104075394201\n",
      "     高壓測試失敗，以太網隔離測試失敗     ===>  TKT-1011 0.5679488905318236\n",
      "     高壓測試失敗，以太網隔離測試失敗     ===>  TKT-1013 0.5764910303659511\n",
      "     高壓測試失敗，以太網隔離測試失敗     ===>  TKT-1023 0.56857286296233\n",
      "     高壓測試不通過，以太網隔離測試失敗     ===>  TKT-1003 0.5825122138382944\n",
      "     高壓測試不通過，以太網隔離測試失敗     ===>  TKT-1007 0.560131003162113\n",
      "     高壓測試不通過，以太網隔離測試失敗     ===>  TKT-1010 0.5698104075394201\n",
      "     高壓測試不通過，以太網隔離測試失敗     ===>  TKT-1011 0.5679488905318236\n",
      "     高壓測試不通過，以太網隔離測試失敗     ===>  TKT-1013 0.5764910303659511\n",
      "     高壓測試不通過，以太網隔離測試失敗     ===>  TKT-1023 0.56857286296233\n",
      "     High-pot test fail, Ethernet isolation test fail     ===>  TKT-1003 0.5825122138382944\n",
      "     High-pot test fail, Ethernet isolation test fail     ===>  TKT-1007 0.560131003162113\n",
      "     High-pot test fail, Ethernet isolation test fail     ===>  TKT-1010 0.5698104075394201\n",
      "     High-pot test fail, Ethernet isolation test fail     ===>  TKT-1011 0.5679488905318236\n",
      "     High-pot test fail, Ethernet isolation test fail     ===>  TKT-1013 0.5764910303659511\n",
      "     High-pot test fail, Ethernet isolation test fail     ===>  TKT-1023 0.56857286296233\n",
      "     Hi-pot test fail and Ethernet isolation fail     ===>  TKT-1003 0.5825122138382944\n",
      "     Hi-pot test fail and Ethernet isolation fail     ===>  TKT-1007 0.560131003162113\n",
      "     Hi-pot test fail and Ethernet isolation fail     ===>  TKT-1010 0.5698104075394201\n",
      "     Hi-pot test fail and Ethernet isolation fail     ===>  TKT-1011 0.5679488905318236\n",
      "     Hi-pot test fail and Ethernet isolation fail     ===>  TKT-1013 0.5764910303659511\n",
      "     Hi-pot test fail and Ethernet isolation fail     ===>  TKT-1023 0.56857286296233\n",
      "高壓測試失敗 以太網隔離失敗     ===>  TKT-1003 0.5825122138382944\n",
      "高壓測試失敗 以太網隔離失敗     ===>  TKT-1007 0.560131003162113\n",
      "高壓測試失敗 以太網隔離失敗     ===>  TKT-1010 0.5698104075394201\n",
      "高壓測試失敗 以太網隔離失敗     ===>  TKT-1011 0.5679488905318236\n",
      "高壓測試失敗 以太網隔離失敗     ===>  TKT-1013 0.5764910303659511\n",
      "高壓測試失敗 以太網隔離失敗     ===>  TKT-1023 0.56857286296233\n",
      "{'Ticket Number': 'TKT-1003', 'Subject': '[HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed', 'Description': '1000 Base-T, Jitter MASTER Filtered failed', 'Resolution': 'NA', 'Current Behavior': 'During testing, the 1000 Base-T, Jitter MASTER Filtered failed.', 'Solution': 'NA (Pending further investigation)', 'Content': '[HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed 1000 Base-T, Jitter MASTER Filtered failed Stage: PVT customer model: CM-9810 HW-Model: HW-MK2.8 HW - CPU Board: Intel i7-10700K HW - Main Board: MB-V2.2 SW - Boot Loader: BL-v3.2 DW - NOS/Diag Ver.: Diag-1.8.6', 'Similarity': 0.5825122138382944}\n",
      "{'Ticket Number': 'TKT-1013', 'Subject': '[EIT] CB_EX3028R_P_Interrupt訊號有異', 'Description': 'CB_EX3028R Interrupt\\r\\nINTn_CPLD_Master_A訊號在回復時，會High兩次，正常情況要直接拉High\\r\\n參考如附件:INTn_CPLD_Master_A', 'Resolution': '', 'Current Behavior': 'Interrupt signal INTn_CPLD_Master_A shows unexpected behavior during recovery.', 'Solution': '', 'Content': '[EIT] CB_EX3028R_P_Interrupt訊號有異 CB_EX3028R Interrupt\\r\\nINTn_CPLD_Master_A訊號在回復時，會High兩次，正常情況要直接拉High\\r\\n參考如附件:INTn_CPLD_Master_A Stage: MP customer model: CB_EX3028R HW-Model: HW-CBM1.2 Switch MAC: N/A Associated SKU: N/A Switch Firmware Version: N/A', 'Similarity': 0.5764910303659511}\n",
      "{'Ticket Number': 'TKT-1010', 'Subject': '[HQA] Overheating observed in CPU intensive tasks', 'Description': \"During CPU intensive tasks, the temperature rose to 90°C. This was observed during a 3D rendering task using software 'Blender'.\", 'Resolution': 'Enhanced thermal dissipation by upgrading the cooling system. Also, applied high-quality thermal paste.', 'Current Behavior': 'Device gets excessively hot when running CPU intensive tasks.', 'Solution': 'Upgraded the cooling system and applied a high-quality thermal paste. Subsequent tests show temperatures well within the safe range.', 'Content': \"[HQA] Overheating observed in CPU intensive tasks During CPU intensive tasks, the temperature rose to 90°C. This was observed during a 3D rendering task using software 'Blender'. Stage: DVT customer model: CM-9801 HW-Model: HW-MK2.8 HW - CPU Board: Intel i9-10900K HW - Main Board: MB-V2.6 SW - Boot Loader: BL-v3.5 DW - NOS/Diag Ver.: Diag-1.7.2\", 'Similarity': 0.5698104075394201}\n",
      "{'Ticket Number': 'TKT-1023', 'Subject': '[HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed', 'Description': '1000 Base-T, Jitter MASTER Filtered failed', 'Resolution': '', 'Current Behavior': 'Jitter MASTER filter test for 1000 Base-T failed.', 'Solution': 'Evaluate the transformer and related components', 'Content': '[HQA] [IEEE]2nd Source FP1 transformer 1000 Base-T, Jitter MASTER Filtered failed 1000 Base-T, Jitter MASTER Filtered failed Stage: EVT Customer Model: ST-ALTA-Switch-32PoE HW-Model: HW-ALTA3.0 HW - CPU Board: CPU-B7 HW - Main Board: MB-ALTA4 SW - Boot Loader: v1.7.1 SW - NOS/Diag Ver.: 2.8.0', 'Similarity': 0.56857286296233}\n",
      "{'Ticket Number': 'TKT-1011', 'Subject': '[EIT]3V3 Power Rail Startup Transients (Rise time fail)', 'Description': 'ST-ALTA-Switch-24PoE Power Rail Startup Transients List as below:\\r\\n\\r\\n3V3 Rise time fail\\r\\nTest Result = 0.321 ms (RTL9301 Spec.>0.5 ms)', 'Resolution': '', 'Current Behavior': \"3V3 rise time doesn't meet the RTL9301 specification.\", 'Solution': '', 'Content': '[EIT]3V3 Power Rail Startup Transients (Rise time fail) ST-ALTA-Switch-24PoE Power Rail Startup Transients List as below:\\r\\n\\r\\n3V3 Rise time fail\\r\\nTest Result = 0.321 ms (RTL9301 Spec.>0.5 ms) Stage: DVT customer model: ST-ALTA-Switch-24PoE HW-Model: HW-RTM3.1 Switch MAC: N/A Associated SKU: N/A Switch Firmware Version: N/A', 'Similarity': 0.5679488905318236}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ---- Step 1: Use Vertex AI LLM to Generate Alternative Queries ----\n",
    "\n",
    "def generate_alternative_queries(project_id: str, location: str, base_query: str, num_alternatives: int = 5):\n",
    "    \"\"\"\n",
    "    Generate alternative queries using Vertex AI LLM.\n",
    "    \"\"\"\n",
    "    \n",
    "    # MAX_RETRIES = 5\n",
    "\n",
    "    parameters = {\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_output_tokens\": 512,\n",
    "        # \"top_p\": 0.8,\n",
    "        # \"top_k\": 40,\n",
    "        # \"stopSequence\" : \"Original Input:\"\n",
    "    }\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison-32k\")\n",
    "    # prompt = f\"Generate {num_alternatives} alternative search queries based on: {base_query}\"\n",
    "    prompt = f\"\"\"\n",
    "Generate {num_alternatives} different versions of the given user question to enhance information retrieval.\n",
    "Do not create anything that is unrelated to the original question, but only use the known inforamtion to form the well structurize question or ask from the differnt way as an QA engineer describing the issue.\n",
    "try to give first two output using Traditional Chinese, the the rest using English.\n",
    "\n",
    "you should only generate 5 lines of questions. First 2 in Traditional Chinese, and following 3 by English.\n",
    "\n",
    "\n",
    "Original Input: CPU Overheating Issue\n",
    "Output: \n",
    "CPU過熱問題\n",
    "CPU渲染任務時過熱\n",
    "CPU overheating during tasks\n",
    "CPU software overheating\n",
    "CPU temperate rises to 90°C\n",
    "\n",
    "Original Input: LED Status Error on Port 44\n",
    "Output: \n",
    "44端口LED問題\n",
    "LED狀態錯誤\n",
    "LED不正常\n",
    "LED port 44 issue\n",
    "44端口燈亮錯誤\n",
    "\n",
    "Original Input: Hi-Pot Test Failure\n",
    "Output:\n",
    "高壓測試失敗\n",
    "Hi-pot test issue\n",
    "Hi-pot測試不通過\n",
    "Hi-pot測試有問題\n",
    "高壓測試不通過\n",
    "\n",
    "(this time you will only generate 5 lines.)\n",
    "Original Input: {base_query}\n",
    "Output:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    response = model.predict(prompt, **parameters)\n",
    "    print(\"response: \", response)\n",
    "    # Assuming the model returns alternatives separated by newlines\n",
    "    queries = response.text.split('\\n')[:num_alternatives]\n",
    "    print(\"queries: \", queries)\n",
    "    return queries\n",
    "\n",
    "# ---- Step 2 & 3: Embed and Search Queries, Apply Voting Mechanism ----\n",
    "\n",
    "def retrieve_and_rank_tickets(base_query: str, num_alternatives: int = 5, top_n: int = 5):\n",
    "    alternative_queries = generate_alternative_queries(os.getenv(\"PROJECT_ID\"), os.getenv(\"LOCATION\"), base_query, num_alternatives)\n",
    "    \n",
    "    alternative_queries.append(base_query)\n",
    "\n",
    "    # Aggregate results from all queries\n",
    "    all_tickets = {}\n",
    "    for query in alternative_queries:\n",
    "        tickets = search_similar_tickets(query)\n",
    "        \n",
    "        # For each ticket, increase its score in all_tickets based on its similarity\n",
    "        for ticket in tickets:\n",
    "            ticket_number = ticket[\"Ticket Number\"]\n",
    "            similarity = ticket[\"Similarity\"]\n",
    "            print(query, \"    ===> \", ticket_number, similarity)\n",
    "            if ticket_number in all_tickets:\n",
    "                all_tickets[ticket_number][\"count\"] += 1\n",
    "                all_tickets[ticket_number][\"cumulative_similarity\"] += similarity\n",
    "            else:\n",
    "                all_tickets[ticket_number] = {\n",
    "                    \"ticket\": ticket,\n",
    "                    \"count\": 1,\n",
    "                    \"cumulative_similarity\": similarity\n",
    "                }\n",
    "    \n",
    "    # Rank by number of appearances and then by cumulative similarity\n",
    "    ranked_tickets = sorted(all_tickets.values(), key=lambda x: (x[\"count\"], x[\"cumulative_similarity\"]), reverse=True)\n",
    "    \n",
    "    # Return the top N tickets based on the ranking\n",
    "    return [ticket[\"ticket\"] for ticket in ranked_tickets[:top_n]]\n",
    "\n",
    "# ---- Test ----\n",
    "user_query = \"高壓測試失敗 以太網隔離失敗\"\n",
    "top_tickets = retrieve_and_rank_tickets(user_query)\n",
    "for ticket in top_tickets:\n",
    "    print(ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f50e4a-1b01-4e60-a374-3d6df485b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ticket Summary:\n",
      "\n",
      "TKT-1003: 1000 Base-T, Jitter MASTER Filtered failed\n",
      "TKT-1013: Interrupt signal INTn_CPLD_Master_A shows unexpected behavior during recovery.\n",
      "TKT-1010: Device gets excessively hot when running CPU intensive tasks.\n",
      "TKT-1023: Jitter MASTER filter test for 1000 Base-T failed.\n",
      "TKT-1011: 3V3 rise time doesn't meet the RTL9301 specification.\n",
      "\n",
      "Most Relevant Tickets:\n",
      "\n",
      "TKT-1003 and TKT-1023 are most relevant to the current user query as they both describe failures related to 1000 Base-T testing.\n",
      "\n",
      "Detailed Analysis:\n",
      "\n",
      "The failures described in TKT-1003 and TKT-1023 are similar in nature, both involving the failure of the 1000 Base-T Jitter MASTER filter test. The root cause of these failures could be related to a faulty transformer or other components in the signal chain. It is also possible that the test setup or procedure was not followed correctly, leading to erroneous results.\n",
      "\n",
      "In TKT-1010, the device was observed to overheat during CPU intensive tasks. This could be due to inadequate thermal dissipation or poor thermal paste application. The resolution involved upgrading the cooling system and applying high-quality thermal paste, which effectively brought the temperatures within a safe range.\n",
      "\n",
      "TKT-1013 describes an issue with the Interrupt signal INTn_CPLD_Master_A, which was observed to have unexpected behavior during recovery. The root cause of this issue is unclear from the ticket description, and further investigation would be required to determine the exact cause.\n",
      "\n",
      "In TKT-1011, the 3V3 power rail startup transient rise time was observed to be below the specified value. This could be due to a number of factors, such as improper component selection or layout issues. Further investigation would be required to identify the root cause of this issue.\n",
      "\n",
      "Recommendations:\n",
      "\n",
      "Based on the analysis of past occurrences, the following recommendations can be made for resolving the current issue:\n",
      "\n",
      "1. For TKT-1003 and TKT-1023, the transformer and related components should be evaluated to identify any potential faults. The test setup and procedure should also be reviewed to ensure that they are correct.\n",
      "\n",
      "2. For TKT-1010, the thermal dissipation of the device should be further enhanced, potentially by adding additional heat sinks or fans. The thermal paste application should also be checked to ensure that it is applied correctly and evenly.\n",
      "\n",
      "3. For TKT-1013, further investigation is required to determine the root cause of the unexpected behavior of the Interrupt signal INTn_CPLD_Master_A. This could involve checking the signal integrity of the relevant traces and components, as well as reviewing the software code that controls the interrupt handling.\n",
      "\n",
      "4. For TKT-1011, the component selection and layout of the 3V3 power rail should be reviewed to identify any potential issues. The power supply and load conditions should also be checked to ensure that they are within the specified range.\n",
      "\n",
      "If these recommendations do not resolve the issue, further investigation and troubleshooting will be required to identify the root cause and implement a suitable solution.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def analyze_bug_using_tickets(project_id: str, location: str, user_query: str, top_tickets: list):\n",
    "    \"\"\"\n",
    "    Generate a detailed report based on the user query and top tickets using the Vertex AI LLM.\n",
    "    \"\"\"\n",
    "    # Create the prompt structure\n",
    "    tickets_str = \"\"\n",
    "    for idx, ticket in enumerate(top_tickets, start=1):\n",
    "        tickets_str += f\"\"\"\n",
    "Ticket {ticket['Ticket Number']}:\n",
    "- Subject: {ticket['Subject']}\n",
    "- Description: {ticket['Description']}\n",
    "- Resolution (if available): {ticket['Resolution']}\n",
    "- Solution (if available): {ticket['Solution']}\n",
    "- Current Behavior: {ticket['Current Behavior']}\n",
    "-----\n",
    "        \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Based on the user's query:\n",
    "\"{user_query}\"\n",
    "\n",
    "And the related bug tickets:\n",
    "{tickets_str}\n",
    "\n",
    "Please perform the following tasks:\n",
    "\n",
    "1. Summarize each ticket briefly.\n",
    "2. Highlight which tickets are most relevant to the current user query.\n",
    "3. Provide a detailed analysis of the potential issue based on these past occurrences. If similar issues have been encountered before, describe their nature and how they were resolved.\n",
    "4. Recommend resolutions or further steps for the current issue based on this historical data. If a similar resolution isn't found, suggest preliminary steps for investigating and potentially resolving this issue.\n",
    "\n",
    "Remember, precision and detail are crucial. Lives depend on this analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set parameters for LLM\n",
    "    parameters = {\n",
    "        \"temperature\": 0.4,\n",
    "        \"max_output_tokens\": 1024\n",
    "    }\n",
    "\n",
    "    # model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison-32k\")\n",
    "    response = model.predict(prompt, **parameters)\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "# Using the function\n",
    "detailed_report = analyze_bug_using_tickets(os.getenv(\"PROJECT_ID\"), os.getenv(\"LOCATION\"), user_query, top_tickets)\n",
    "print(detailed_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01f3cfb6-1388-4458-966a-1b08330f3f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting streamlit_bug_ticket_analysis.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile streamlit_bug_ticket_analysis.py\n",
    "\n",
    "import streamlit as st\n",
    "from google.cloud import aiplatform, sql\n",
    "from google.cloud.sql.connector import Connector\n",
    "\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "import time\n",
    "import asyncio\n",
    "import asyncpg\n",
    "import numpy as np\n",
    "from pgvector.asyncpg import register_vector\n",
    "\n",
    "import sqlalchemy\n",
    "\n",
    "\n",
    "import vertexai\n",
    "# from vertexai.language_models import TextGenerationModel\n",
    "from vertexai.preview.language_models import TextGenerationModel\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "\n",
    "\n",
    "\n",
    "# Constants\n",
    "COLUMNS = {\n",
    "    \"Ticket Number\": 0,\n",
    "    \"Subject\": 1,\n",
    "    \"Description\": 2,\n",
    "    \"Resolution\": 3,\n",
    "    \"Current Behavior\": 4,\n",
    "    \"Solution\": 5,\n",
    "    \"Content\": 6,\n",
    "    \"Similarity\": 7\n",
    "}  # Keeping it the same as in original code... mapping to postgresDB\n",
    "\n",
    "project_id = \"rust-ry\"\n",
    "region = \"us-central1\"\n",
    "instance_name = \"liteon-bug-tickets-demo\"\n",
    "database_name = \"mybugticket\"\n",
    "database_user = \"ry-admin\"     \n",
    "database_password = \"rust123\"  \n",
    "\n",
    "# ---- Functions (as you provided, with minor modifications) ----\n",
    "def connect_with_connector() -> sqlalchemy.engine.base.Engine:\n",
    "    connector = Connector()\n",
    "    return sqlalchemy.create_engine(\n",
    "        \"postgresql+pg8000://\",\n",
    "        creator=lambda: connector.connect(\n",
    "            os.getenv(\"INSTANCE_CONNECTION_NAME\"),\n",
    "            \"pg8000\",\n",
    "            user=os.getenv(\"DB_USER\"),\n",
    "            password=os.getenv(\"DB_PASS\"),\n",
    "            db=os.getenv(\"DB_NAME\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "# def get_embedding_for_query(query: str):\n",
    "#     model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-multilingual@latest\")\n",
    "#     instance = {\"task_type\": \"RETRIEVAL_QUERY\", \"content\": query}\n",
    "#     return model.get_embeddings([instance])[0].values\n",
    "\n",
    "def get_embedding_for_query(query: str):\n",
    "    model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko-multilingual@latest\")\n",
    "    instance = {\n",
    "        \"instances\": [{\n",
    "            \"task_type\": \"RETRIEVAL_QUERY\",\n",
    "            \"content\": query\n",
    "        }]\n",
    "    }\n",
    "    embeddings = model.get_embeddings(instance)\n",
    "    return embeddings[0].values\n",
    "\n",
    "def search_similar_tickets(user_query: str, \n",
    "                           search_method: str = \"cosine\",\n",
    "                           similarity_threshold: float = 0.001,\n",
    "                           num_matches: int = 6) -> list:\n",
    "    assert user_query, \"⚠️ Please input a valid search query\"\n",
    "\n",
    "    qe = get_embedding_for_query(user_query)\n",
    "    distance_function = {\n",
    "        \"cosine\": \"<=>\",\n",
    "        \"inner_product\": \"<#>\",\n",
    "        \"euclidean\": \"<->\"\n",
    "    }.get(search_method, \"<=>\")\n",
    "\n",
    "    with connect_with_connector().connect() as db_conn:\n",
    "        query = f\"\"\"\n",
    "            WITH vector_matches AS (\n",
    "                SELECT ticket_number, 1 - (embedding {distance_function} :embedding) AS similarity\n",
    "                FROM ticket_data\n",
    "                WHERE 1 - (embedding {distance_function} :embedding) > :similarity_threshold\n",
    "                ORDER BY similarity DESC\n",
    "                LIMIT :num_matches\n",
    "            )\n",
    "            SELECT \n",
    "                t.ticket_number, t.subject, t.description, t.resolution,\n",
    "                t.current_behavior, t.solution, t.content, vm.similarity\n",
    "            FROM ticket_data AS t\n",
    "            JOIN vector_matches AS vm ON t.ticket_number = vm.ticket_number\n",
    "        \"\"\"\n",
    "\n",
    "        parameters = {\n",
    "            \"embedding\": \"[\" + \",\".join(map(str, qe)) + \"]\",\n",
    "            \"similarity_threshold\": similarity_threshold,\n",
    "            \"num_matches\": num_matches\n",
    "        }\n",
    "\n",
    "        results = db_conn.execute(sqlalchemy.text(query), parameters).fetchall()\n",
    "        matches = [\n",
    "            {column_name: row[index] for column_name, index in COLUMNS.items()}\n",
    "            for row in results\n",
    "        ]\n",
    "\n",
    "    return matches\n",
    "\n",
    "# # Sample Call\n",
    "# tickets = search_similar_tickets(user_query=\"100M isn't work well\")\n",
    "# print(tickets)\n",
    "\n",
    "#beautiful priting function, in markdown format.\n",
    "def print_tickets_markdown(tickets: list):\n",
    "    \"\"\"\n",
    "    Prints the list of tickets in a markdown format.\n",
    "    \"\"\"\n",
    "    for idx, ticket in enumerate(tickets, start=1):\n",
    "        print(\"#\" * 3 + f\" Ticket #{idx}\")\n",
    "        \n",
    "        for key, value in ticket.items():\n",
    "            # Beautify certain lengthy fields to display better.\n",
    "            if key in [\"Description\", \"Content\", \"Current Behavior\", \"Solution\"]:\n",
    "                value = \"\\n\\n\" + \"\\n\".join(f\"- {line}\" for line in value.splitlines())\n",
    "\n",
    "            # Format the similarity score to be more readable.\n",
    "            if key == \"Similarity\":\n",
    "                value = f\"{value:.4f}\"\n",
    "\n",
    "            print(f\"**{key}**: {value}\\n\")\n",
    "        print(\"---\\n\\n\")\n",
    "\n",
    "# Sample Call\n",
    "# print_tickets_markdown(tickets)\n",
    "\n",
    "\n",
    "# ---- Step 1: Use Vertex AI LLM to Generate Alternative Queries ----\n",
    "\n",
    "def generate_alternative_queries(project_id: str, location: str, base_query: str, num_alternatives: int = 5, temperature: float = 0.25):\n",
    "    \"\"\"\n",
    "    Generate alternative queries using Vertex AI LLM.\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        \"temperature\": temperature,\n",
    "        \"max_output_tokens\": 512,\n",
    "        # \"top_p\": 0.8,\n",
    "        # \"top_k\": 40,\n",
    "        # \"stopSequence\" : \"Original Input:\"\n",
    "    }\n",
    "\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison-32k\")\n",
    "    # prompt = f\"Generate {num_alternatives} alternative search queries based on: {base_query}\"\n",
    "    prompt = f\"\"\"\n",
    "Generate {num_alternatives} different versions of the given user question to enhance information retrieval.\n",
    "Do not create anything that is unrelated to the original question, but only use the known inforamtion to form the well structurize question or ask from the differnt way as an QA engineer describing the issue.\n",
    "try to give first two output using Traditional Chinese, the the rest using English.\n",
    "\n",
    "you should only generate 5 lines of questions. and do not output other things.\n",
    "\n",
    "\n",
    "Original Input: CPU Overheating Issue\n",
    "Output: \n",
    "CPU過熱問題\n",
    "CPU渲染任務時過熱\n",
    "CPU overheating during tasks\n",
    "CPU software overheating\n",
    "CPU temperate rises to 90°C\n",
    "\n",
    "Original Input: LED Status Error on Port 44\n",
    "Output: \n",
    "44端口LED問題\n",
    "LED狀態錯誤\n",
    "LED不正常\n",
    "LED port 44 issue\n",
    "44端口燈亮錯誤\n",
    "\n",
    "Original Input: Hi-Pot Test Failure\n",
    "Output:\n",
    "高壓測試失敗\n",
    "Hi-pot test issue\n",
    "Hi-pot測試不通過\n",
    "Hi-pot測試有問題\n",
    "高壓測試不通過\n",
    "\n",
    "\n",
    "Original Input: {base_query}\n",
    "Output:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    response = model.predict(prompt, **parameters)\n",
    "    print(\"response: \", response)\n",
    "    # Assuming the model returns alternatives separated by newlines\n",
    "    queries = response.text.split('\\n')[:num_alternatives]\n",
    "    print(\"queries: \", queries)\n",
    "    return queries\n",
    "\n",
    "# ---- Step 2 & 3: Embed and Search Queries, Apply Voting Mechanism ----\n",
    "\n",
    "def retrieve_and_rank_tickets(base_query: str, num_alternatives: int = 5, top_n: int = 5, temperature: float = 0.25):\n",
    "    alternative_queries = generate_alternative_queries(os.getenv(\"PROJECT_ID\"), os.getenv(\"LOCATION\"), base_query, num_alternatives, temperature)\n",
    "    \n",
    "    alternative_queries.append(base_query)\n",
    "\n",
    "    # Aggregate results from all queries\n",
    "    all_tickets = {}\n",
    "    for query in alternative_queries:\n",
    "        tickets = search_similar_tickets(query)\n",
    "        \n",
    "        # For each ticket, increase its score in all_tickets based on its similarity\n",
    "        for ticket in tickets:\n",
    "            ticket_number = ticket[\"Ticket Number\"]\n",
    "            similarity = ticket[\"Similarity\"]\n",
    "            print(query, \"    ===> \", ticket_number, similarity)\n",
    "            if ticket_number in all_tickets:\n",
    "                all_tickets[ticket_number][\"count\"] += 1\n",
    "                all_tickets[ticket_number][\"cumulative_similarity\"] += similarity\n",
    "            else:\n",
    "                all_tickets[ticket_number] = {\n",
    "                    \"ticket\": ticket,\n",
    "                    \"count\": 1,\n",
    "                    \"cumulative_similarity\": similarity\n",
    "                }\n",
    "    \n",
    "    # Rank by number of appearances and then by cumulative similarity\n",
    "    ranked_tickets = sorted(all_tickets.values(), key=lambda x: (x[\"count\"], x[\"cumulative_similarity\"]), reverse=True)\n",
    "    \n",
    "    # Return the top N tickets based on the ranking\n",
    "    return [ticket[\"ticket\"] for ticket in ranked_tickets[:top_n]]\n",
    "\n",
    "\n",
    "def analyze_bug_using_tickets(project_id: str, location: str, user_query: str, top_tickets: list):\n",
    "    \"\"\"\n",
    "    Generate a detailed report based on the user query and top tickets using the Vertex AI LLM.\n",
    "    \"\"\"\n",
    "    # Create the prompt structure\n",
    "    tickets_str = \"\"\n",
    "    for idx, ticket in enumerate(top_tickets, start=1):\n",
    "        tickets_str += f\"\"\"\n",
    "Ticket {ticket['Ticket Number']}:\n",
    "- Subject: {ticket['Subject']}\n",
    "- Description: {ticket['Description']}\n",
    "- Resolution (if available): {ticket['Resolution']}\n",
    "- Solution (if available): {ticket['Solution']}\n",
    "- Current Behavior: {ticket['Current Behavior']}\n",
    "-----\n",
    "        \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Based on the user's query:\n",
    "\"{user_query}\"\n",
    "\n",
    "And the related bug tickets:\n",
    "{tickets_str}\n",
    "\n",
    "Please perform the following tasks:\n",
    "\n",
    "1. Summarize each ticket briefly.\n",
    "2. Highlight which tickets are most relevant to the current user query.\n",
    "3. Provide a detailed analysis of the potential issue based on these past occurrences. If similar issues have been encountered before, describe their nature and how they were resolved.\n",
    "4. Recommend resolutions or further steps for the current issue based on this historical data. If a similar resolution isn't found, suggest preliminary steps for investigating and potentially resolving this issue.\n",
    "\n",
    "Remember, precision and detail are crucial. Lives depend on this analysis.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set parameters for LLM\n",
    "    parameters = {\n",
    "        \"temperature\": 0.4,\n",
    "        \"max_output_tokens\": 1024\n",
    "    }\n",
    "\n",
    "    # model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison-32k\")\n",
    "    response = model.predict(prompt, **parameters)\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "def analyze_bug_using_tickets_tc(project_id: str, location: str, user_query: str, top_tickets: list):\n",
    "    \"\"\"\n",
    "    Generate a detailed report based on the user query and top tickets using the Vertex AI LLM.\n",
    "    \"\"\"\n",
    "    # Create the prompt structure\n",
    "    tickets_str = \"\"\n",
    "    for idx, ticket in enumerate(top_tickets, start=1):\n",
    "        tickets_str += f\"\"\"\n",
    "Ticket {ticket['Ticket Number']}:\n",
    "- Subject: {ticket['Subject']}\n",
    "- Description: {ticket['Description']}\n",
    "- Resolution (if available): {ticket['Resolution']}\n",
    "- Solution (if available): {ticket['Solution']}\n",
    "- Current Behavior: {ticket['Current Behavior']}\n",
    "-----\n",
    "        \"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Based on the user's query:\n",
    "\"{user_query}\"\n",
    "\n",
    "And the related bug tickets:\n",
    "{tickets_str}\n",
    "\n",
    "Please perform the following tasks:\n",
    "\n",
    "1. Summarize each ticket briefly.\n",
    "2. Highlight which tickets are most relevant to the current user query.\n",
    "3. Provide a detailed analysis of the potential issue based on these past occurrences. If similar issues have been encountered before, describe their nature and how they were resolved.\n",
    "4. Recommend resolutions or further steps for the current issue based on this historical data. If a similar resolution isn't found, suggest preliminary steps for investigating and potentially resolving this issue.\n",
    "\n",
    "Remember, precision and detail are crucial. Lives depend on this analysis.\n",
    "用台灣的語言回答，僅有專有名詞及專業術語使用英文，讓整體的語句越流暢越好\n",
    "    \"\"\"\n",
    "\n",
    "    # Set parameters for LLM\n",
    "    parameters = {\n",
    "        \"temperature\": 0.4,\n",
    "        \"max_output_tokens\": 1024\n",
    "    }\n",
    "\n",
    "    # model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "    model = TextGenerationModel.from_pretrained(\"text-bison-32k\")\n",
    "    response = model.predict(prompt, **parameters)\n",
    "    \n",
    "    return response.text\n",
    "\n",
    "\n",
    "\n",
    "# ... (above is all functions: connect_with_connector, get_embedding_for_query, search_similar_tickets... etc.)\n",
    "\n",
    "# Streamlit UI\n",
    "\n",
    "# Initialize Streamlit's session state for language choice\n",
    "if 'selected_language' not in st.session_state:\n",
    "    st.session_state.selected_language = \"English\"\n",
    "\n",
    "st.title(\"Advanced Ticket Analysis System\")\n",
    "st.sidebar.header(\"Configuration\")\n",
    "\n",
    "\n",
    "# Move language selection to sidebar\n",
    "\n",
    "\n",
    "# User Inputs\n",
    "user_query = st.text_input(\"Enter your issue/query:\", \"Ripple Noise test fail\")\n",
    "search_method = st.sidebar.selectbox(\"Search Method\", [\"cosine\", \"inner_product\", \"euclidean\"], index=0)\n",
    "temperature = st.sidebar.slider(\"Temperature\", 0.0, 0.9, 0.5)\n",
    "num_matches = st.sidebar.slider(\"Number of Matches\", 1, 20, 6)\n",
    "similarity_threshold = st.sidebar.slider(\"Similarity Threshold\", 0.0, 1.0, 0.001)\n",
    "language_selection = st.sidebar.radio(\n",
    "    \"Choose Analysis Language\", [\"English\", \"Traditional Chinese\"]\n",
    ")\n",
    "\n",
    "# If the Analyze button is pressed\n",
    "if st.button(\"Analyze\"):\n",
    "    # Generate Alternative Queries\n",
    "    alternative_queries = generate_alternative_queries(project_id, region, user_query, 5 , temperature)\n",
    "    alternative_queries.append(user_query)\n",
    "\n",
    "    # Search similar tickets for each query\n",
    "    all_found_tickets = []\n",
    "    for query in alternative_queries:\n",
    "        tickets = search_similar_tickets(query, search_method, similarity_threshold, num_matches)\n",
    "        all_found_tickets.extend(tickets)\n",
    "\n",
    "    # Display matched ticket details in Streamlit\n",
    "    st.subheader(\"Top Matched Ticket Details\")\n",
    "    for idx, ticket in enumerate(all_found_tickets[:10], start=1):\n",
    "        st.markdown(f\"### Ticket {idx}: {ticket['Ticket Number']}\")\n",
    "        st.write(f\"**Subject**: {ticket['Subject']}\")\n",
    "        st.write(f\"**Similarity Score**: {ticket['Similarity']:.4f}\")\n",
    "\n",
    "        # Use Streamlit's expander for each section\n",
    "        with st.expander(\"Description\"):\n",
    "            st.write(ticket['Description'])\n",
    "\n",
    "        if ticket.get('Resolution'):\n",
    "            with st.expander(\"Resolution\"):\n",
    "                st.write(ticket['Resolution'])\n",
    "\n",
    "        if ticket.get('Solution'):\n",
    "            with st.expander(\"Solution\"):\n",
    "                st.write(ticket['Solution'])\n",
    "\n",
    "        if ticket.get('Current Behavior'):\n",
    "            with st.expander(\"Current Behavior\"):\n",
    "                st.write(ticket['Current Behavior'])\n",
    "\n",
    "        # Can continue this for other fields if necessary\n",
    "        st.write(\"---\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Analyze bug using top tickets\n",
    "    st.subheader(\"Detailed Analysis and Recommendations\")\n",
    "    # Use the value of language_selection to decide the language\n",
    "    if language_selection == \"English\":\n",
    "        detailed_report = analyze_bug_using_tickets(project_id, region, user_query, all_found_tickets[:5])\n",
    "        st.write(detailed_report)\n",
    "    elif language_selection == \"Traditional Chinese\":\n",
    "        detailed_report_tc = analyze_bug_using_tickets_tc(project_id, region, user_query, all_found_tickets[:5])\n",
    "        st.write(detailed_report_tc)\n",
    "\n",
    "\n",
    "\n",
    "st.warning(\"\"\"Please review and validate AI-generated results. Human judgment is critical, especially in crucial situations.\n",
    "\n",
    "           請查看並驗證人工智慧產生的結果。人類的判斷至關重要，尤其是在關鍵情況下 ver 0925 0823。\"\"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    st.write(\"Streamlit Application for Advanced Ticket Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b606ac0-52ad-4f95-9f96-6b95fb5b6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !npm i localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a70b436-ba00-47f7-90d9-443d6483488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['project-ID:region:DB-instance-name']: An error occurred while performing refresh. Scheduling another refresh attempt immediately\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 388, in _refresh_task\n",
      "    refresh_data = await refresh_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 312, in _perform_refresh\n",
      "    metadata = await metadata_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/refresh_utils.py\", line 101, in _get_metadata\n",
      "    resp = await client_session.get(url, headers=headers, raise_for_status=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 643, in _request\n",
      "    resp.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client_reqrep.py\", line 1005, in raise_for_status\n",
      "    raise ClientResponseError(\n",
      "aiohttp.client_exceptions.ClientResponseError: 400, message='Bad Request', url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-348' coro=<Instance._schedule_refresh.<locals>._refresh_task() done, defined at /opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py:377> exception=ClientResponseError(RequestInfo(url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings'), method='GET', headers=<CIMultiDictProxy('Host': 'sqladmin.googleapis.com', 'x-goog-api-client': 'cloud-sql-python-connector/1.2.3+pg8000', 'User-Agent': 'cloud-sql-python-connector/1.2.3+pg8000', 'Content-Type': 'application/json', 'Authorization': 'Bearer ya29.c.b0Aaekm1JgeM2JOWw5yvUDuYa1-ApUCj7ksh-5r_6cYtyP0covv69Wcy-w4h4prjnUeNMiBnjS9xCu40BuqbRbrT-dp7tstfklQ99766m0KSWV2ua9pbv-jWNZCeAg8GKcGir4kA-O2TLHCdcJZJyfauTnAmXOSJyJW1UaYPH0jGMb2luR7hSZAChk5N9adH3d7Nh4mgqOG1alZTkmdiOwYekDpz60leknxdt8klPmSWAA6jlRhgo5r2bH-YfAXhjAsAwcVdtP0GezDV-gcfp1J-4pJxRXD_6Ry8oolDmPaRQoPBM1Ea9IiREugsZCmzSxtDG4DBdthu4LvEMuOyJvskV2dZwwIGKvSn7VyOtzmQT371ArYV9l1b471J_5s3iVSt63Borw67BIqZgsUt9u7kM8S73Veeu0tFaMVxURz5vJmZOy-bVoeXUSUbJpndxJOXYx_wB0JZ_h6BqhRJodU-wBaOvS8VdRe71ZBjJ8nqs9WcoRuev42ymcUxubbftmnkv6Mins1-XOsycZ2IUnbWf7g1rd2_3B0q-99io8OhmVfSnWvMhJMt7y-v9ss94u1mvbqpalZoI9lRi9Xm81Ulpix8J15jfBeFIIMtUa2Vs3O2ZaMcvdWF9_kXmJbnQ1azqpwnx6t3zB7qzr-qS1FlV958oVx7muzkh1ovZn96cpRoRnkuZ_vBYoxvuvh92xzRacVSvB8x22vbz8YUMcYZ8SjklJwOlzFvl-X61ijORz8n3tzBUe2xQ-x5zoW4mSr-huck1BXSvigQ8_WkUnU4eUvjq10363id9Qe4rs7k1k5wZU4hZQMdS606eB86aw8mwbg71vfSMjYMs7tmZhX-YIuYas-B6sOZJzWk4MWkO9SyXWff1FWu31FpjrjxkoxfY_q-1jsXb7dQXIOUJXm_i9-J1l2OIckrMSiyqiB0M19j7k7lcJZa4p0_dV1j-uBap8dWY9-QwX-51S1yvBVhnei0J_c_w5odexwoWkX0bxo7k9fqql_Ut', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate')>, real_url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')), (), status=400, message='Bad Request', headers=<CIMultiDictProxy('Vary': 'Origin', 'Vary': 'X-Origin', 'Vary': 'Referer', 'Content-Type': 'application/json; charset=UTF-8', 'Content-Encoding': 'gzip', 'Date': 'Mon, 25 Sep 2023 12:40:26 GMT', 'Server': 'ESF', 'Cache-Control': 'private', 'X-XSS-Protection': '0', 'X-Frame-Options': 'SAMEORIGIN', 'X-Content-Type-Options': 'nosniff', 'Transfer-Encoding': 'chunked')>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 388, in _refresh_task\n",
      "    refresh_data = await refresh_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 312, in _perform_refresh\n",
      "    metadata = await metadata_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/refresh_utils.py\", line 101, in _get_metadata\n",
      "    resp = await client_session.get(url, headers=headers, raise_for_status=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 643, in _request\n",
      "    resp.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client_reqrep.py\", line 1005, in raise_for_status\n",
      "    raise ClientResponseError(\n",
      "aiohttp.client_exceptions.ClientResponseError: 400, message='Bad Request', url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')\n",
      "['project-ID:region:DB-instance-name']: An error occurred while performing refresh. Scheduling another refresh attempt immediately\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 388, in _refresh_task\n",
      "    refresh_data = await refresh_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 312, in _perform_refresh\n",
      "    metadata = await metadata_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/refresh_utils.py\", line 101, in _get_metadata\n",
      "    resp = await client_session.get(url, headers=headers, raise_for_status=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 643, in _request\n",
      "    resp.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client_reqrep.py\", line 1005, in raise_for_status\n",
      "    raise ClientResponseError(\n",
      "aiohttp.client_exceptions.ClientResponseError: 400, message='Bad Request', url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-357' coro=<Instance._schedule_refresh.<locals>._refresh_task() done, defined at /opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py:377> exception=ClientResponseError(RequestInfo(url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings'), method='GET', headers=<CIMultiDictProxy('Host': 'sqladmin.googleapis.com', 'x-goog-api-client': 'cloud-sql-python-connector/1.2.3+pg8000', 'User-Agent': 'cloud-sql-python-connector/1.2.3+pg8000', 'Content-Type': 'application/json', 'Authorization': 'Bearer ya29.c.b0Aaekm1JgeM2JOWw5yvUDuYa1-ApUCj7ksh-5r_6cYtyP0covv69Wcy-w4h4prjnUeNMiBnjS9xCu40BuqbRbrT-dp7tstfklQ99766m0KSWV2ua9pbv-jWNZCeAg8GKcGir4kA-O2TLHCdcJZJyfauTnAmXOSJyJW1UaYPH0jGMb2luR7hSZAChk5N9adH3d7Nh4mgqOG1alZTkmdiOwYekDpz60leknxdt8klPmSWAA6jlRhgo5r2bH-YfAXhjAsAwcVdtP0GezDV-gcfp1J-4pJxRXD_6Ry8oolDmPaRQoPBM1Ea9IiREugsZCmzSxtDG4DBdthu4LvEMuOyJvskV2dZwwIGKvSn7VyOtzmQT371ArYV9l1b471J_5s3iVSt63Borw67BIqZgsUt9u7kM8S73Veeu0tFaMVxURz5vJmZOy-bVoeXUSUbJpndxJOXYx_wB0JZ_h6BqhRJodU-wBaOvS8VdRe71ZBjJ8nqs9WcoRuev42ymcUxubbftmnkv6Mins1-XOsycZ2IUnbWf7g1rd2_3B0q-99io8OhmVfSnWvMhJMt7y-v9ss94u1mvbqpalZoI9lRi9Xm81Ulpix8J15jfBeFIIMtUa2Vs3O2ZaMcvdWF9_kXmJbnQ1azqpwnx6t3zB7qzr-qS1FlV958oVx7muzkh1ovZn96cpRoRnkuZ_vBYoxvuvh92xzRacVSvB8x22vbz8YUMcYZ8SjklJwOlzFvl-X61ijORz8n3tzBUe2xQ-x5zoW4mSr-huck1BXSvigQ8_WkUnU4eUvjq10363id9Qe4rs7k1k5wZU4hZQMdS606eB86aw8mwbg71vfSMjYMs7tmZhX-YIuYas-B6sOZJzWk4MWkO9SyXWff1FWu31FpjrjxkoxfY_q-1jsXb7dQXIOUJXm_i9-J1l2OIckrMSiyqiB0M19j7k7lcJZa4p0_dV1j-uBap8dWY9-QwX-51S1yvBVhnei0J_c_w5odexwoWkX0bxo7k9fqql_Ut', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate')>, real_url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')), (), status=400, message='Bad Request', headers=<CIMultiDictProxy('Vary': 'Origin', 'Vary': 'X-Origin', 'Vary': 'Referer', 'Content-Type': 'application/json; charset=UTF-8', 'Content-Encoding': 'gzip', 'Date': 'Mon, 25 Sep 2023 12:40:56 GMT', 'Server': 'ESF', 'Cache-Control': 'private', 'X-XSS-Protection': '0', 'X-Frame-Options': 'SAMEORIGIN', 'X-Content-Type-Options': 'nosniff', 'Transfer-Encoding': 'chunked')>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 388, in _refresh_task\n",
      "    refresh_data = await refresh_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 312, in _perform_refresh\n",
      "    metadata = await metadata_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/refresh_utils.py\", line 101, in _get_metadata\n",
      "    resp = await client_session.get(url, headers=headers, raise_for_status=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 643, in _request\n",
      "    resp.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client_reqrep.py\", line 1005, in raise_for_status\n",
      "    raise ClientResponseError(\n",
      "aiohttp.client_exceptions.ClientResponseError: 400, message='Bad Request', url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')\n",
      "['project-ID:region:DB-instance-name']: An error occurred while performing refresh. Scheduling another refresh attempt immediately\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 388, in _refresh_task\n",
      "    refresh_data = await refresh_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 312, in _perform_refresh\n",
      "    metadata = await metadata_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/refresh_utils.py\", line 101, in _get_metadata\n",
      "    resp = await client_session.get(url, headers=headers, raise_for_status=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 643, in _request\n",
      "    resp.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client_reqrep.py\", line 1005, in raise_for_status\n",
      "    raise ClientResponseError(\n",
      "aiohttp.client_exceptions.ClientResponseError: 400, message='Bad Request', url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-366' coro=<Instance._schedule_refresh.<locals>._refresh_task() done, defined at /opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py:377> exception=ClientResponseError(RequestInfo(url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings'), method='GET', headers=<CIMultiDictProxy('Host': 'sqladmin.googleapis.com', 'x-goog-api-client': 'cloud-sql-python-connector/1.2.3+pg8000', 'User-Agent': 'cloud-sql-python-connector/1.2.3+pg8000', 'Content-Type': 'application/json', 'Authorization': 'Bearer ya29.c.b0Aaekm1JgeM2JOWw5yvUDuYa1-ApUCj7ksh-5r_6cYtyP0covv69Wcy-w4h4prjnUeNMiBnjS9xCu40BuqbRbrT-dp7tstfklQ99766m0KSWV2ua9pbv-jWNZCeAg8GKcGir4kA-O2TLHCdcJZJyfauTnAmXOSJyJW1UaYPH0jGMb2luR7hSZAChk5N9adH3d7Nh4mgqOG1alZTkmdiOwYekDpz60leknxdt8klPmSWAA6jlRhgo5r2bH-YfAXhjAsAwcVdtP0GezDV-gcfp1J-4pJxRXD_6Ry8oolDmPaRQoPBM1Ea9IiREugsZCmzSxtDG4DBdthu4LvEMuOyJvskV2dZwwIGKvSn7VyOtzmQT371ArYV9l1b471J_5s3iVSt63Borw67BIqZgsUt9u7kM8S73Veeu0tFaMVxURz5vJmZOy-bVoeXUSUbJpndxJOXYx_wB0JZ_h6BqhRJodU-wBaOvS8VdRe71ZBjJ8nqs9WcoRuev42ymcUxubbftmnkv6Mins1-XOsycZ2IUnbWf7g1rd2_3B0q-99io8OhmVfSnWvMhJMt7y-v9ss94u1mvbqpalZoI9lRi9Xm81Ulpix8J15jfBeFIIMtUa2Vs3O2ZaMcvdWF9_kXmJbnQ1azqpwnx6t3zB7qzr-qS1FlV958oVx7muzkh1ovZn96cpRoRnkuZ_vBYoxvuvh92xzRacVSvB8x22vbz8YUMcYZ8SjklJwOlzFvl-X61ijORz8n3tzBUe2xQ-x5zoW4mSr-huck1BXSvigQ8_WkUnU4eUvjq10363id9Qe4rs7k1k5wZU4hZQMdS606eB86aw8mwbg71vfSMjYMs7tmZhX-YIuYas-B6sOZJzWk4MWkO9SyXWff1FWu31FpjrjxkoxfY_q-1jsXb7dQXIOUJXm_i9-J1l2OIckrMSiyqiB0M19j7k7lcJZa4p0_dV1j-uBap8dWY9-QwX-51S1yvBVhnei0J_c_w5odexwoWkX0bxo7k9fqql_Ut', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate')>, real_url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')), (), status=400, message='Bad Request', headers=<CIMultiDictProxy('Vary': 'Origin', 'Vary': 'X-Origin', 'Vary': 'Referer', 'Content-Type': 'application/json; charset=UTF-8', 'Content-Encoding': 'gzip', 'Date': 'Mon, 25 Sep 2023 12:41:26 GMT', 'Server': 'ESF', 'Cache-Control': 'private', 'X-XSS-Protection': '0', 'X-Frame-Options': 'SAMEORIGIN', 'X-Content-Type-Options': 'nosniff', 'Transfer-Encoding': 'chunked')>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 388, in _refresh_task\n",
      "    refresh_data = await refresh_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 312, in _perform_refresh\n",
      "    metadata = await metadata_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/refresh_utils.py\", line 101, in _get_metadata\n",
      "    resp = await client_session.get(url, headers=headers, raise_for_status=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 643, in _request\n",
      "    resp.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client_reqrep.py\", line 1005, in raise_for_status\n",
      "    raise ClientResponseError(\n",
      "aiohttp.client_exceptions.ClientResponseError: 400, message='Bad Request', url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')\n",
      "['project-ID:region:DB-instance-name']: An error occurred while performing refresh. Scheduling another refresh attempt immediately\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 388, in _refresh_task\n",
      "    refresh_data = await refresh_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 312, in _perform_refresh\n",
      "    metadata = await metadata_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/refresh_utils.py\", line 101, in _get_metadata\n",
      "    resp = await client_session.get(url, headers=headers, raise_for_status=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 643, in _request\n",
      "    resp.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client_reqrep.py\", line 1005, in raise_for_status\n",
      "    raise ClientResponseError(\n",
      "aiohttp.client_exceptions.ClientResponseError: 400, message='Bad Request', url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-375' coro=<Instance._schedule_refresh.<locals>._refresh_task() done, defined at /opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py:377> exception=ClientResponseError(RequestInfo(url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings'), method='GET', headers=<CIMultiDictProxy('Host': 'sqladmin.googleapis.com', 'x-goog-api-client': 'cloud-sql-python-connector/1.2.3+pg8000', 'User-Agent': 'cloud-sql-python-connector/1.2.3+pg8000', 'Content-Type': 'application/json', 'Authorization': 'Bearer ya29.c.b0Aaekm1JgeM2JOWw5yvUDuYa1-ApUCj7ksh-5r_6cYtyP0covv69Wcy-w4h4prjnUeNMiBnjS9xCu40BuqbRbrT-dp7tstfklQ99766m0KSWV2ua9pbv-jWNZCeAg8GKcGir4kA-O2TLHCdcJZJyfauTnAmXOSJyJW1UaYPH0jGMb2luR7hSZAChk5N9adH3d7Nh4mgqOG1alZTkmdiOwYekDpz60leknxdt8klPmSWAA6jlRhgo5r2bH-YfAXhjAsAwcVdtP0GezDV-gcfp1J-4pJxRXD_6Ry8oolDmPaRQoPBM1Ea9IiREugsZCmzSxtDG4DBdthu4LvEMuOyJvskV2dZwwIGKvSn7VyOtzmQT371ArYV9l1b471J_5s3iVSt63Borw67BIqZgsUt9u7kM8S73Veeu0tFaMVxURz5vJmZOy-bVoeXUSUbJpndxJOXYx_wB0JZ_h6BqhRJodU-wBaOvS8VdRe71ZBjJ8nqs9WcoRuev42ymcUxubbftmnkv6Mins1-XOsycZ2IUnbWf7g1rd2_3B0q-99io8OhmVfSnWvMhJMt7y-v9ss94u1mvbqpalZoI9lRi9Xm81Ulpix8J15jfBeFIIMtUa2Vs3O2ZaMcvdWF9_kXmJbnQ1azqpwnx6t3zB7qzr-qS1FlV958oVx7muzkh1ovZn96cpRoRnkuZ_vBYoxvuvh92xzRacVSvB8x22vbz8YUMcYZ8SjklJwOlzFvl-X61ijORz8n3tzBUe2xQ-x5zoW4mSr-huck1BXSvigQ8_WkUnU4eUvjq10363id9Qe4rs7k1k5wZU4hZQMdS606eB86aw8mwbg71vfSMjYMs7tmZhX-YIuYas-B6sOZJzWk4MWkO9SyXWff1FWu31FpjrjxkoxfY_q-1jsXb7dQXIOUJXm_i9-J1l2OIckrMSiyqiB0M19j7k7lcJZa4p0_dV1j-uBap8dWY9-QwX-51S1yvBVhnei0J_c_w5odexwoWkX0bxo7k9fqql_Ut', 'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate')>, real_url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')), (), status=400, message='Bad Request', headers=<CIMultiDictProxy('Vary': 'Origin', 'Vary': 'X-Origin', 'Vary': 'Referer', 'Content-Type': 'application/json; charset=UTF-8', 'Content-Encoding': 'gzip', 'Date': 'Mon, 25 Sep 2023 12:41:56 GMT', 'Server': 'ESF', 'Cache-Control': 'private', 'X-XSS-Protection': '0', 'X-Frame-Options': 'SAMEORIGIN', 'X-Content-Type-Options': 'nosniff', 'Transfer-Encoding': 'chunked')>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 388, in _refresh_task\n",
      "    refresh_data = await refresh_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/instance.py\", line 312, in _perform_refresh\n",
      "    metadata = await metadata_task\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/google/cloud/sql/connector/refresh_utils.py\", line 101, in _get_metadata\n",
      "    resp = await client_session.get(url, headers=headers, raise_for_status=True)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client.py\", line 643, in _request\n",
      "    resp.raise_for_status()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/aiohttp/client_reqrep.py\", line 1005, in raise_for_status\n",
      "    raise ClientResponseError(\n",
      "aiohttp.client_exceptions.ClientResponseError: 400, message='Bad Request', url=URL('https://sqladmin.googleapis.com/sql/v1beta4/projects/project-ID/instances/DB-instance-name/connectSettings')\n"
     ]
    }
   ],
   "source": [
    "!streamlit run streamlit_bug_ticket_analysis.py & npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a775a-95f9-4188-83ff-d896707f35bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
